{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQL76jAqgATRuTL3Q2as0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorkemeris/Basic-Deep-Learning-Example/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOoJumXYZ_0U"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "\n",
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[0]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[permutation,:,:,:]\n",
        "    shuffled_Y = Y[permutation,:]\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches\n",
        "\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "\n",
        "\n",
        "def forward_propagation_for_predict(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3'] \n",
        "                                                           # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
        "    \n",
        "    return Z3\n",
        "\n",
        "def predict(X, parameters):\n",
        "    \n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.placeholder(\"float\", [12288, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction\n",
        "\n",
        "#def predict(X, parameters):\n",
        "#    \n",
        "#    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "#    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "#    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "#    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "##    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "##    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "#    \n",
        "##    params = {\"W1\": W1,\n",
        "##              \"b1\": b1,\n",
        "##              \"W2\": W2,\n",
        "##              \"b2\": b2,\n",
        "##              \"W3\": W3,\n",
        "##              \"b3\": b3}\n",
        "#\n",
        "#    params = {\"W1\": W1,\n",
        "#              \"b1\": b1,\n",
        "#              \"W2\": W2,\n",
        "#              \"b2\": b2}    \n",
        "#    \n",
        "#    x = tf.placeholder(\"float\", [12288, 1])\n",
        "#    \n",
        "#    z3 = forward_propagation(x, params)\n",
        "#    p = tf.argmax(z3)\n",
        "#    \n",
        "#    with tf.Session() as sess:\n",
        "#        prediction = sess.run(p, feed_dict = {x: X})\n",
        "#        \n",
        "#    return prediction"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJN-xe50adlp"
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NyNsmKOaduj"
      },
      "source": [
        "def zero_pad(X, pad):\n",
        "  X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad),(0,0)), 'constant', constant_values=(0, 0))\n",
        "  return X_pad"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QDzQ17kadzM",
        "outputId": "12591afe-851e-4a1e-f0e4-80a3ff500199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_pad(x, 2)\n",
        "print (\"x.shape =\", x.shape)\n",
        "print (\"x_pad.shape =\", x_pad.shape)\n",
        "print (\"x[1,1] =\", x[1,1])\n",
        "print (\"x_pad[1,1] =\", x_pad[1,1])\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0,:,:,0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0,:,:,0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape = (4, 3, 3, 2)\n",
            "x_pad.shape = (4, 7, 7, 2)\n",
            "x[1,1] = [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] = [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc39cd676a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHn_bEM5ad2D"
      },
      "source": [
        "def conv_single_step(a_slice_prev,W,b):\n",
        "  s = a_slice_prev*W\n",
        "  Z = np.sum(s)\n",
        "  Z = float(Z+b)\n",
        "  return Z"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cno3RcM2ad4c",
        "outputId": "4531bd33-b090-44c5-b5da-c5a98f50d72b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = -6.999089450680221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a0JVQMMad7E"
      },
      "source": [
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n",
        "    \n",
        "    # Retrieve dimensions from W's shape (≈1 line)\n",
        "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
        "    \n",
        "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)\n",
        "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
        "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
        "    \n",
        "    # Initialize the output volume Z with zeros. (≈1 line)\n",
        "\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Create A_prev_pad by padding A_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "\n",
        "    for i in range(m):                                  # loop over the batch of training examples\n",
        "        a_prev_pad = A_prev_pad[i,:,:,:]                # Select ith training example's padded activation\n",
        "        for h in range(n_H):                           # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = h * stride+ f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = w * stride + f\n",
        "                    \n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
        "                    \n",
        "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev,W[:,:,:,c], b[:,:,:,c])\n",
        "             \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-klJvclyc6He",
        "outputId": "c321d27f-79e4-43ad-b261-02c1bd300491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10,4,4,3)\n",
        "W = np.random.randn(2,2,3,8)\n",
        "b = np.random.randn(1,1,1,8)\n",
        "hparameters = {\"pad\" : 2,\n",
        "               \"stride\": 2}\n",
        "\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "print(\"Z's mean =\", np.mean(Z))\n",
        "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
        "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z's mean = 0.048995203528855794\n",
            "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
            "  5.18531798  8.75898442]\n",
            "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCUdFkxqc6Ju"
      },
      "source": [
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "\n",
        "    \n",
        "    # Retrieve dimensions from the input shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    for i in range(m):                         # loop over the training examples\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                for c in range (n_C):            # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = h * stride+ f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = w * stride + f\n",
        "                    \n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end,c]\n",
        "                    \n",
        "                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.\n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(A.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    return A, cache"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X0n0pdEc6L-",
        "outputId": "9a52c14e-0bca-4013-d648-4d5715cd3a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 4, 4, 3)\n",
        "hparameters = {\"stride\" : 2, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A =\", A)\n",
        "print()\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A =\", A)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A = [[[[1.74481176 0.86540763 1.13376944]]]\n",
            "\n",
            "\n",
            " [[[1.13162939 1.51981682 2.18557541]]]]\n",
            "\n",
            "mode = average\n",
            "A = [[[[ 0.02105773 -0.20328806 -0.40389855]]]\n",
            "\n",
            "\n",
            " [[[-0.22154621  0.51716526  0.48155844]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbAbAQopdEnT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A92ocK82dExj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUFTz_AydE3b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}